{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd454c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import torch\n",
    "import random\n",
    "from torch.autograd import Variable as V\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "init = True\n",
    "images_dir = \"/scratch/alexandel91/single_frames\"\n",
    "save_dir = \"/scratch/agnek95/Unreal/CNN_activations_redone/2D_ResNet18/extracted/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd696e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 1: LOAD RESNET2D MODEL #\n",
    "# Set random seeds (especially important for random initialization)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Set the architecture to use\n",
    "arch = \"resnet18\"\n",
    "\n",
    "model_file = \"%s_places365.pth.tar\" % arch\n",
    "\n",
    "if not os.access(model_file, os.W_OK):\n",
    "    weight_url = (\n",
    "        \"http://places2.csail.mit.edu/models_places365/\" + model_file\n",
    "    )\n",
    "    os.system(\"wget \" + weight_url)\n",
    "\n",
    "# New syntax\n",
    "model = models.resnet18(num_classes=365, weights=None)\n",
    "if init:  # Initialize model with pre-trained weights\n",
    "    save_dir = save_dir + \"_pretrained\"\n",
    "    checkpoint = torch.load(\n",
    "        model_file, map_location=lambda storage, loc: storage\n",
    "    )\n",
    "    state_dict = {\n",
    "        str.replace(k, \"module.\", \"\"): v\n",
    "        for k, v in checkpoint[\"state_dict\"].items()\n",
    "    }\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# STEP 2: DEFINE DATA VARIABLES #\n",
    "# number of images\n",
    "num_videos = 1440\n",
    "\n",
    "# load the image transformer to transform the image to the required format\n",
    "centre_crop = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --------------------------------------\n",
    "# STEP 3: EXTRACT UNIT ACTIVATIONS #\n",
    "# --------------------------------------\n",
    "return_layers = [\"layer1.0.relu_1\", \"layer1.1.relu_1\", \"layer2.0.relu_1\", \"layer2.1.relu_1\", \"layer3.0.relu_1\", \"layer3.1.relu_1\", \"layer4.0.relu_1\", \"layer4.1.relu_1\"]\n",
    "\n",
    "# First dimension refers to # of feature maps or channels\n",
    "layer1_0_s = np.zeros((64, 56, 56))\n",
    "layer1_1_s = np.zeros((64, 56, 56))\n",
    "layer2_0_s = np.zeros((128, 28, 28))\n",
    "layer2_1_s = np.zeros((128, 28, 28))\n",
    "layer3_0_s = np.zeros((256, 14, 14))\n",
    "layer3_1_s = np.zeros((256, 14, 14))\n",
    "layer4_0_s = np.zeros((512, 7, 7))\n",
    "layer4_1_s = np.zeros((512, 7, 7))\n",
    "\n",
    "# Number of units per layer\n",
    "num_col_1_0 = 64*56*56\n",
    "num_col_1_1 = 64*56*56\n",
    "num_col_2_0 = 128*28*28\n",
    "num_col_2_1 = 128*28*28\n",
    "num_col_3_0 = 256*14*14\n",
    "num_col_3_1 = 256*14*14\n",
    "num_col_4_0 = 512*7*7\n",
    "num_col_4_1 = 512*7*7\n",
    "\n",
    "layer1_0_features = np.zeros((1440, num_col_1_0))\n",
    "layer1_1_features = np.zeros((1440, num_col_1_1))\n",
    "layer2_0_features = np.zeros((1440, num_col_2_0))\n",
    "layer2_1_features = np.zeros((1440, num_col_2_1))\n",
    "layer3_0_features = np.zeros((1440, num_col_3_0))\n",
    "layer3_1_features = np.zeros((1440, num_col_3_1))\n",
    "layer4_0_features = np.zeros((1440, num_col_4_0))\n",
    "layer4_1_features = np.zeros((1440, num_col_4_1))\n",
    "\n",
    "# Extract features\n",
    "train_nodes, eval_nodes = get_graph_node_names(model)\n",
    "\n",
    "# checker whether nodes are same for training and evaluation mode\n",
    "assert [t == e for t, e in zip(train_nodes, eval_nodes)]\n",
    "\n",
    "feature_extractor = create_feature_extractor(\n",
    "    model, return_nodes=return_layers\n",
    ")\n",
    "\n",
    "# Loop through all images\n",
    "print(\"Extracting features...\")\n",
    "for img in tqdm(range(1, (num_videos + 1))):\n",
    "    idx = img - 1\n",
    "\n",
    "    image_dir = os.path.join(images_dir, (f\"{img:04}_frame_20.jpg\"))\n",
    "\n",
    "    # Load image\n",
    "    image = Image.open(image_dir)\n",
    "\n",
    "    # Preprocess image\n",
    "    batch_t = V(centre_crop(image).unsqueeze(0))\n",
    "\n",
    "    # apply those features on image\n",
    "    with torch.no_grad():\n",
    "        out = feature_extractor(batch_t)\n",
    "\n",
    "    for _, layer in enumerate(return_layers):\n",
    "        # pick layer\n",
    "        feat_maps = out[layer].numpy().squeeze(0)\n",
    "\n",
    "        if layer == \"layer1.0.relu_1\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "                flatten_fm = feat_maps[fm]\n",
    "                layer1_0_s[fm, :, :] = flatten_fm\n",
    "            layer1_0_features[idx, :] = layer1_0_s.flatten()\n",
    "        elif layer == \"layer1.1.relu_1\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "                flatten_fm = feat_maps[fm]\n",
    "                layer1_1_s[fm, :, :] = flatten_fm\n",
    "            layer1_1_features[idx, :] = layer1_1_s.flatten()\n",
    "        elif layer == \"layer2.0.relu_1\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "                flatten_fm = feat_maps[fm]\n",
    "                layer2_0_s[fm, :, :] = flatten_fm\n",
    "            layer2_0_features[idx, :] = layer2_0_s.flatten()\n",
    "        elif layer == \"layer2.1.relu_1\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "                flatten_fm = feat_maps[fm]\n",
    "                layer2_1_s[fm, :, :] = flatten_fm\n",
    "            layer2_1_features[idx, :] = layer2_1_s.flatten()\n",
    "        elif layer == \"layer3.0.relu_1\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "                flatten_fm = feat_maps[fm]\n",
    "                layer3_0_s[fm, :, :] = flatten_fm\n",
    "            layer3_0_features[idx, :] = layer3_0_s.flatten()\n",
    "        elif layer == \"layer3.1.relu_1\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "                flatten_fm = feat_maps[fm]\n",
    "                layer3_1_s[fm, :, :] = flatten_fm\n",
    "            layer3_1_features[idx, :] = layer3_1_s.flatten()\n",
    "        elif layer == \"layer4.0.relu_1\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "                flatten_fm = feat_maps[fm]\n",
    "                layer4_0_s[fm, :, :] = flatten_fm\n",
    "            layer4_0_features[idx, :] = layer4_0_s.flatten()\n",
    "        elif layer == \"layer4.1.relu_1\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "                flatten_fm = feat_maps[fm]\n",
    "                layer4_1_s[fm, :, :] = flatten_fm\n",
    "            layer4_1_features[idx, :] = layer4_1_s.flatten()\n",
    "\n",
    "# --------------------------------------\n",
    "# STEP 4: SAVE FEATURES WITHOUT PCA #\n",
    "# --------------------------------------\n",
    "# Save each layer separately\n",
    "features = {\n",
    "    \"layer1.0.relu_1\": layer1_0_features,\n",
    "    \"layer1.1.relu_1\": layer1_1_features,\n",
    "    \"layer2.0.relu_1\": layer2_0_features,\n",
    "    \"layer2.1.relu_1\": layer2_1_features,\n",
    "    \"layer3.0.relu_1\": layer3_0_features,\n",
    "    \"layer3.1.relu_1\": layer3_1_features,\n",
    "    \"layer4.0.relu_1\": layer4_0_features,\n",
    "    \"layer4.1.relu_1\": layer4_1_features\n",
    "}\n",
    "\n",
    "print(type(features)) \n",
    "for layer in features.keys():\n",
    "    print(\"Check\")\n",
    "    features_dir = save_dir + \"/\" + \"new_features_resnet_\" + layer + \".pkl\"\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    with open(features_dir, \"wb\") as f:\n",
    "        pickle.dump(features[layer], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
