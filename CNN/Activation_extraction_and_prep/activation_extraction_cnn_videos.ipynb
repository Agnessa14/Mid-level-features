{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9832ce-2cf2-4f3f-8ef3-1d50706b90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.io.video import read_video\n",
    "from torchvision.models.video import r3d_18\n",
    "from torchvision.models.video import R3D_18_Weights\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "init = True\n",
    "miniclips_dir = \"/scratch/alexandel91/miniclips_30\"\n",
    "save_dir = \"/scratch/agnek95/Unreal/CNN_activations_redone/3D_ResNet18/extracted/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca5090-4008-494f-8f86-19ed827f4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# STEP 1: LOAD RESNET3D MODEL #\n",
    "# --------------------------------------\n",
    "\n",
    "# Set random seeds (especially important for random initialization)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Load pretrained weights\n",
    "if init:\n",
    "    # save_dir = save_dir + \"_pretrained\"\n",
    "    resnet_video = r3d_18(weights=\"KINETICS400_V1\")\n",
    "else:\n",
    "    resnet_video = r3d_18(weights=None, progress=True)\n",
    "\n",
    "# define transformation procedure for images (aka preprocessing)\n",
    "preprocess = R3D_18_Weights.DEFAULT.transforms()\n",
    "\n",
    "# --------------------------------------\n",
    "# STEP 2: DEFINE DATA VARIABLES #\n",
    "# --------------------------------------\n",
    "\n",
    "# number of videos\n",
    "num_videos = sum(1 for file in os.scandir(miniclips_dir) if file.is_file())\n",
    "\n",
    "if num_videos != 1440:\n",
    "    raise ValueError(\"Number of videos is not 1440\")\n",
    "\n",
    "# number of frames\n",
    "num_frames = 9\n",
    "\n",
    "# --------------------------------------\n",
    "# STEP 3: EXTRACT UNIT ACTIVATIONS #\n",
    "# --------------------------------------\n",
    "return_layers = [\"layer1.0.relu\", \"layer1.1.relu\", \"layer2.0.relu\", \"layer2.1.relu\", \"layer3.0.relu\", \"layer3.1.relu\", \"layer4.0.relu\", \"layer4.1.relu\"]\n",
    "\n",
    "# dimensions or num entries in each feature map in different layers\n",
    "num_col_1_0 = 56*56\n",
    "num_col_1_1 = 56*56\n",
    "num_col_2_0 = 28*28\n",
    "num_col_2_1 = 28*28\n",
    "num_col_3_0 = 14*14\n",
    "num_col_3_1 = 14*14\n",
    "num_col_4_0 = 7*7\n",
    "num_col_4_1 = 7*7\n",
    "\n",
    "num_feat_maps_1_0 = 64\n",
    "num_feat_maps_1_1 = 64\n",
    "num_feat_maps_2_0 = 128\n",
    "num_feat_maps_2_1 = 128\n",
    "num_feat_maps_3_0 = 256 \n",
    "num_feat_maps_3_1 = 256\n",
    "num_feat_maps_4_0 = 512\n",
    "num_feat_maps_4_1 = 512\n",
    "\n",
    "\n",
    "# array for activations per video - First dimension refers to # of feature maps or channels\n",
    "layer1_0_features_s = np.zeros((64, num_col_1_0))\n",
    "layer1_1_features_s = np.zeros((64, num_col_1_1))\n",
    "layer2_0_features_s = np.zeros((128, num_col_2_0))\n",
    "layer2_1_features_s = np.zeros((128, num_col_2_1))\n",
    "layer3_0_features_s = np.zeros((256, num_col_3_0))\n",
    "layer3_1_features_s = np.zeros((256, num_col_3_1))\n",
    "layer4_0_features_s = np.zeros((512, num_col_4_0))\n",
    "layer4_1_features_s = np.zeros((512, num_col_4_1))\n",
    "\n",
    "#array for saving flattened activations across videos\n",
    "layer1_0_features = np.zeros((1440, num_col_1_0 * num_feat_maps_1_0))\n",
    "layer1_1_features = np.zeros((1440, num_col_1_1 * num_feat_maps_1_1))\n",
    "layer2_0_features = np.zeros((1440, num_col_2_0 * num_feat_maps_2_0))\n",
    "layer2_1_features = np.zeros((1440, num_col_2_1 * num_feat_maps_2_1))\n",
    "layer3_0_features = np.zeros((1440, num_col_3_0 * num_feat_maps_3_0))\n",
    "layer3_1_features = np.zeros((1440, num_col_3_1 * num_feat_maps_3_1))\n",
    "layer4_0_features = np.zeros((1440, num_col_4_0 * num_feat_maps_4_0))\n",
    "layer4_1_features = np.zeros((1440, num_col_4_1 * num_feat_maps_4_1))\n",
    "\n",
    "# Extract features\n",
    "train_nodes, eval_nodes = get_graph_node_names(resnet_video)\n",
    "\n",
    "# checker whether nodes are same for training and evaluation mode\n",
    "assert [t == e for t, e in zip(train_nodes, eval_nodes)]\n",
    "\n",
    "feature_extractor = create_feature_extractor(\n",
    "    resnet_video, return_nodes=return_layers\n",
    ")\n",
    "\n",
    "print(\"Extracting features...\")\n",
    "for img in tqdm(range(1, (num_videos + 1))):\n",
    "    idx = img - 1\n",
    "\n",
    "    # Get video directory (here referred to as image)\n",
    "    image_file = str(img).zfill(4) + \".mp4\"  # zfill: fill with zeros (4)\n",
    "    image_dir = miniclips_dir + \"/\" + image_file\n",
    "\n",
    "    # Load video\n",
    "    video, _, _ = read_video(image_dir, output_format=\"TCHW\")\n",
    "\n",
    "    video_preprocessed = preprocess(video)\n",
    "\n",
    "    batch_t = video_preprocessed.unsqueeze(0)\n",
    "\n",
    "    # Activate the evaluation mode of the DNN\n",
    "    resnet_video.eval()\n",
    "\n",
    "    # apply those features on image\n",
    "    with torch.no_grad():\n",
    "        out = feature_extractor(batch_t)\n",
    "\n",
    "    for _, layer in enumerate(return_layers):\n",
    "        # pick layer\n",
    "        feat_maps = out[layer].numpy().squeeze(0)\n",
    "\n",
    "        if layer == \"layer1.0.relu\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "\n",
    "                flatten_fm_final = np.zeros((1, num_col_1_0))\n",
    "                for frame in range(9):\n",
    "                    flatten_fm = feat_maps[fm, frame, :, :].flatten()\n",
    "                    flatten_fm_final = np.add(flatten_fm_final, flatten_fm)\n",
    "\n",
    "                flatten_fm_final = np.divide(flatten_fm_final, num_frames)\n",
    "                layer1_0_features_s[fm, :] = flatten_fm_final\n",
    "\n",
    "            layer1_0_features[idx, :] = layer1_0_features_s.flatten()\n",
    " \n",
    "        elif layer == \"layer1.1.relu\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "\n",
    "                flatten_fm_final = np.zeros((1, num_col_1_1))\n",
    "                for frame in range(9):\n",
    "                    flatten_fm = feat_maps[fm, frame, :, :].flatten()\n",
    "                    flatten_fm_final = np.add(flatten_fm_final, flatten_fm)\n",
    "\n",
    "                flatten_fm_final = np.divide(flatten_fm_final, num_frames)\n",
    "                layer1_1_features_s[fm, :] = flatten_fm_final\n",
    "\n",
    "            layer1_1_features[idx, :] = layer1_1_features_s.flatten()\n",
    "            \n",
    "        elif layer == \"layer2.0.relu\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "\n",
    "                flatten_fm_final = np.zeros((1, num_col_2_0))\n",
    "                for frame in range(5):\n",
    "                    flatten_fm = feat_maps[fm, frame, :, :].flatten()\n",
    "                    flatten_fm_final = np.add(flatten_fm_final, flatten_fm)\n",
    "\n",
    "                flatten_fm_final = np.divide(flatten_fm_final, num_frames)\n",
    "                layer2_0_features_s[fm, :] = flatten_fm_final\n",
    "\n",
    "            layer2_0_features[idx, :] = layer2_0_features_s.flatten()\n",
    "            \n",
    "        elif layer == \"layer2.1.relu\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "\n",
    "                flatten_fm_final = np.zeros((1, num_col_2_1))\n",
    "                for frame in range(5):\n",
    "                    flatten_fm = feat_maps[fm, frame, :, :].flatten()\n",
    "                    flatten_fm_final = np.add(flatten_fm_final, flatten_fm)\n",
    "\n",
    "                flatten_fm_final = np.divide(flatten_fm_final, num_frames)\n",
    "                layer2_1_features_s[fm, :] = flatten_fm_final\n",
    "\n",
    "            layer2_1_features[idx, :] = layer2_1_features_s.flatten()\n",
    "            \n",
    "        elif layer == \"layer3.0.relu\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "\n",
    "                flatten_fm_final = np.zeros((1, num_col_3_0))\n",
    "                for frame in range(3):\n",
    "                    flatten_fm = feat_maps[fm, frame, :, :].flatten()\n",
    "                    flatten_fm_final = np.add(flatten_fm_final, flatten_fm)\n",
    "\n",
    "                flatten_fm_final = np.divide(flatten_fm_final, num_frames)\n",
    "                layer3_0_features_s[fm, :] = flatten_fm_final\n",
    "\n",
    "            layer3_0_features[idx, :] = layer3_0_features_s.flatten()\n",
    "            \n",
    "        elif layer == \"layer3.1.relu\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "\n",
    "                flatten_fm_final = np.zeros((1, num_col_3_1))\n",
    "                for frame in range(3):\n",
    "                    flatten_fm = feat_maps[fm, frame, :, :].flatten()\n",
    "                    flatten_fm_final = np.add(flatten_fm_final, flatten_fm)\n",
    "\n",
    "                flatten_fm_final = np.divide(flatten_fm_final, num_frames)\n",
    "                layer3_1_features_s[fm, :] = flatten_fm_final\n",
    "\n",
    "            layer3_1_features[idx, :] = layer3_1_features_s.flatten()\n",
    "            \n",
    "        elif layer == \"layer4.0.relu\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "\n",
    "                flatten_fm_final = np.zeros((1, num_col_4_0))\n",
    "                for frame in range(2):\n",
    "                    flatten_fm = feat_maps[fm, frame, :, :].flatten()\n",
    "                    flatten_fm_final = np.add(flatten_fm_final, flatten_fm)\n",
    "\n",
    "                flatten_fm_final = np.divide(flatten_fm_final, num_frames)\n",
    "                layer4_0_features_s[fm, :] = flatten_fm_final\n",
    "\n",
    "            layer4_0_features[idx, :] = layer4_0_features_s.flatten()\n",
    "            \n",
    "        elif layer == \"layer4.1.relu\":\n",
    "            for fm in range(len(list(feat_maps))):\n",
    "\n",
    "                flatten_fm_final = np.zeros((1, num_col_4_1))\n",
    "                for frame in range(2):\n",
    "                    flatten_fm = feat_maps[fm, frame, :, :].flatten()\n",
    "                    flatten_fm_final = np.add(flatten_fm_final, flatten_fm)\n",
    "\n",
    "                flatten_fm_final = np.divide(flatten_fm_final, num_frames)\n",
    "                layer4_1_features_s[fm, :] = flatten_fm_final\n",
    "\n",
    "            layer4_1_features[idx, :] = layer4_1_features_s.flatten()\n",
    "# --------------------------------------\n",
    "# STEP 4: SAVE FEATURES WITHOUT PCA #\n",
    "# --------------------------------------\n",
    "try:\n",
    "    print(layer1_0_features)\n",
    "    contains_only_zeros = np.all(layer1_0_features == 0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Save each layer separately\n",
    "features = {\n",
    "    \"layer1.0.relu_1\": layer1_0_features,\n",
    "    \"layer1.1.relu_1\": layer1_1_features,\n",
    "    \"layer2.0.relu_1\": layer2_0_features,\n",
    "    \"layer2.1.relu_1\": layer2_1_features,\n",
    "    \"layer3.0.relu_1\": layer3_0_features,\n",
    "    \"layer3.1.relu_1\": layer3_1_features,\n",
    "    \"layer4.0.relu_1\": layer4_0_features,\n",
    "    \"layer4.1.relu_1\": layer4_1_features\n",
    "}\n",
    "\n",
    "print(type(features)) \n",
    "for layer in features.keys():\n",
    "    print(\"Check\")\n",
    "    features_dir = save_dir + \"/\" + \"new_features_resnet_\" + layer + \".pkl\"\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    with open(features_dir, \"wb\") as f:\n",
    "        pickle.dump(features[layer], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
